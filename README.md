# BROIL_ALP

This project has 3 main goals:

* Combine Robust Inverse Reinforcement Learning (RIRL) with Aproximate Linear Programming (ALP)
* Extend this concept to combine ALP and Byasian Robust Optimization for Imiation Learning (BROIL)
* Use these methods to solve COVID-19 lockdown stratagy as a controll problem

We can title the overarching stratagy Robust Value Approximation (RoVA).
We can our first method Approximate Robust Linear Programming for Imitation Learning (ARLP-IL)
We can further call our second appoach Baysian Approximate Robust Imiation Learning (BARIL)

Finally we justify COVID-19 lockdown strategy as an ideal candidate for these methods, as there are many possible reward functions that a government may try to optimize when constructing a lockdown policy. In this case on may want to find a lockdown policy that is robust to the worst case senarois for each of these possible reward functions.
